{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a038c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e4f2ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PreferedAlbum</th>\n",
       "      <th>Vinyl</th>\n",
       "      <th>AvgTime</th>\n",
       "      <th>TicketInfo</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Concert</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>Food</th>\n",
       "      <th>Drinks</th>\n",
       "      <th>FreePass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/2362</td>\n",
       "      <td>Head Hunters</td>\n",
       "      <td>False</td>\n",
       "      <td>3.055</td>\n",
       "      <td>B/140/N</td>\n",
       "      <td>Everything worked, yet nothing surprised me. (...</td>\n",
       "      <td>NYC12-5pm</td>\n",
       "      <td>22.0</td>\n",
       "      <td>False</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/0599</td>\n",
       "      <td>Bright Size Life</td>\n",
       "      <td>True</td>\n",
       "      <td>2.510</td>\n",
       "      <td>LB/124/N</td>\n",
       "      <td>Solid gig—nothing magical, nothing awful. (NYC...</td>\n",
       "      <td>NYC12-5pm</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/3223</td>\n",
       "      <td>Head Hunters</td>\n",
       "      <td>False</td>\n",
       "      <td>0.803</td>\n",
       "      <td>CB/523/N</td>\n",
       "      <td>Guitars were sharp, but everything else felt r...</td>\n",
       "      <td>NYC12-5pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>815.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/1966</td>\n",
       "      <td>Kind of Blue</td>\n",
       "      <td>False</td>\n",
       "      <td>0.568</td>\n",
       "      <td>A/81/XL</td>\n",
       "      <td>Feedback screamed louder than the guitars. Dis...</td>\n",
       "      <td>FL16-7pm</td>\n",
       "      <td>36.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/8850</td>\n",
       "      <td>Bright Size Life</td>\n",
       "      <td>False</td>\n",
       "      <td>0.034</td>\n",
       "      <td>B/580/XL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC12-5pm</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id     PreferedAlbum  Vinyl  AvgTime TicketInfo  \\\n",
       "0  01/2362      Head Hunters  False    3.055    B/140/N   \n",
       "1  04/0599  Bright Size Life   True    2.510   LB/124/N   \n",
       "2  01/3223      Head Hunters  False    0.803   CB/523/N   \n",
       "3  01/1966      Kind of Blue  False    0.568    A/81/XL   \n",
       "4  01/8850  Bright Size Life  False    0.034   B/580/XL   \n",
       "\n",
       "                                             Opinion    Concert   Age    VIP  \\\n",
       "0  Everything worked, yet nothing surprised me. (...  NYC12-5pm  22.0  False   \n",
       "1  Solid gig—nothing magical, nothing awful. (NYC...  NYC12-5pm   9.0  False   \n",
       "2  Guitars were sharp, but everything else felt r...  NYC12-5pm   NaN  False   \n",
       "3  Feedback screamed louder than the guitars. Dis...   FL16-7pm  36.0  False   \n",
       "4                                                NaN  NYC12-5pm  16.0  False   \n",
       "\n",
       "     Food  Drinks  FreePass  \n",
       "0   170.0     1.0      True  \n",
       "1     0.0     0.0      True  \n",
       "2   815.0    37.0     False  \n",
       "3  1427.0  1395.0     False  \n",
       "4  1299.0     0.0     False  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('complex-master-learn-and-get-your-mark/train.csv')\n",
    "df_test = pd.read_csv('complex-master-learn-and-get-your-mark/test.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f34f65c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c481d631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='FreePass', ylabel='AvgTime'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(df[\"AvgTime\"] > 2)[\"FreePass\"].mean()\n",
    "import seaborn as sns\n",
    "sns.boxplot(x=\"FreePass\", y=\"AvgTime\", data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Id\", \"FreePass\"])\n",
    "y = df[\"FreePass\"].astype(int)\n",
    "\n",
    "num_cols = X.select_dtypes(include=\"float64\").columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "clf_logreg = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=100,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    "))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8117c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anica\\anaconda33\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.4099999999999998\n",
      "Best F1: 0.8033866415804327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# =====================\n",
    "# 1. Feature engineering\n",
    "# =====================\n",
    "X_fe = X.copy()\n",
    "\n",
    "# Interacciones simples (mejoran LR)\n",
    "X_fe[\"Food_Drinks\"] = X_fe[\"Food\"] + X_fe[\"Drinks\"]\n",
    "X_fe[\"Spending\"] = X_fe[\"Food\"] * X_fe[\"Drinks\"]\n",
    "\n",
    "# Quitamos la variable con leakage\n",
    "X_fe = X_fe.drop(columns=[\"AvgTime\"])\n",
    "\n",
    "# =====================\n",
    "# 2. Columnas\n",
    "# =====================\n",
    "X_fe['Age'] = X_fe['Age'].fillna(X_fe['Age'].median())\n",
    "X_fe['Age_Group'] = pd.cut(X_fe['Age'], \n",
    "                          bins=[0, 25, 35, 45, 55, 100],\n",
    "                          labels=['<25', '25-35', '35-45', '45-55', '55+'])\n",
    "X_fe['Is_Young'] = (X_fe['Age'] < 30).astype(int)\n",
    "X_fe['Is_Senior'] = (X_fe['Age'] > 50).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Opinion simple\n",
    "X_fe['Opinion_Length'] = X_fe['Opinion'].str.len().fillna(0)\n",
    "X_fe['Has_Opinion'] = X_fe['Opinion'].notna().astype(int)\n",
    "\n",
    "\n",
    "# Sentimiento básico\n",
    "def simple_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    pos_words = ['good', 'great', 'excellent', 'amazing', 'love', 'best', 'awesome', 'perfect', 'fantastic']\n",
    "    neg_words = ['bad', 'worst', 'terrible', 'awful', 'hate', 'disappointing', 'poor', 'boring', 'waste']\n",
    "    \n",
    "    pos_count = sum(1 for word in pos_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in neg_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return 1\n",
    "    elif neg_count > pos_count:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "X_fe['Sentiment'] = X['Opinion'].apply(simple_sentiment)\n",
    "X_fe['Sentiment_Score'] = X_fe['Sentiment'].astype(int)\n",
    "\n",
    "\n",
    "# ========= TicketInfo parsing =========\n",
    "X_fe[\"Ticket_Zone\"] = X[\"TicketInfo\"].str.split(\"/\").str[0]\n",
    "X_fe[\"Ticket_Row\"] = X[\"TicketInfo\"].str.split(\"/\").str[1].astype(float)\n",
    "X_fe[\"Ticket_Size\"] = X[\"TicketInfo\"].str.split(\"/\").str[2]\n",
    "X_fe['Is_Front_Row'] = (X_fe['Ticket_Row'] <= 10).astype(int)\n",
    "\n",
    "for col in ['PreferedAlbum', 'Concert', 'Ticket_Zone', 'Ticket_Size']:\n",
    "    X_fe[col] = X_fe[col].fillna('Unknown')\n",
    "\n",
    "for col in X_fe.columns:\n",
    "    if X_fe[col].dtype == 'bool':\n",
    "        X_fe[col] = X_fe[col].astype(int)\n",
    "\n",
    "\n",
    "num_cols = X_fe.select_dtypes(\"float64\").columns\n",
    "cat_cols = X_fe.select_dtypes(\"object\").columns\n",
    "\n",
    "# =====================\n",
    "# 3. Pipelines (LOS TUYOS, sin cambiar filosofía)\n",
    "# =====================\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\",\n",
    "        min_frequency=20   # reduce ruido de categorías raras\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "selector = SelectFromModel(\n",
    "    LogisticRegression(penalty=\"l1\", solver=\"saga\", C=0.1)\n",
    ")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 4. Modelo\n",
    "# =====================\n",
    "clf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"selector\", selector),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l1\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf_gb = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# =====================\n",
    "# 5. Train / validation\n",
    "# =====================\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_fe,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# =====================\n",
    "# 6. Threshold óptimo\n",
    "# =====================\n",
    "y_probs = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "scores = [f1_score(y_val, y_probs > t) for t in thresholds]\n",
    "\n",
    "best_threshold = thresholds[np.argmax(scores)]\n",
    "best_score = max(scores)\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Best F1:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6347f9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODELO 1: Random Forest\n",
      "============================================================\n",
      "Accuracy: 0.7964\n",
      "F1 Score: 0.7870\n",
      "ROC AUC: 0.8941\n",
      "\n",
      "============================================================\n",
      "MODELO 2: Gradient Boosting\n",
      "============================================================\n",
      "Accuracy: 0.8241\n",
      "F1 Score: 0.8255\n",
      "ROC AUC: 0.9085\n",
      "\n",
      "============================================================\n",
      "MODELO 3: HistGradientBoosting (Recomendado)\n",
      "============================================================\n",
      "Accuracy: 0.8142\n",
      "F1 Score: 0.8144\n",
      "ROC AUC: 0.9077\n",
      "\n",
      "============================================================\n",
      "MODELO 4: k-Nearest Neighbors\n",
      "============================================================\n",
      "Accuracy: 0.8009\n",
      "F1 Score: 0.7945\n",
      "ROC AUC: 0.8739\n",
      "\n",
      "============================================================\n",
      "MODELO 5: Logistic Regression (L1)\n",
      "============================================================\n",
      "Accuracy: 0.7925\n",
      "F1 Score: 0.7848\n",
      "ROC AUC: 0.8800\n",
      "\n",
      "============================================================\n",
      "COMPARATIVA DE MODELOS\n",
      "============================================================\n",
      "               Model  Accuracy  F1 Score  ROC AUC\n",
      "   Gradient Boosting  0.824111  0.825490 0.908511\n",
      "HistGradientBoosting  0.814229  0.814413 0.907704\n",
      "                 KNN  0.800889  0.794493 0.873871\n",
      "       Random Forest  0.796443  0.786970 0.894132\n",
      " Logistic Regression  0.792490  0.784836 0.880024\n",
      "\n",
      "============================================================\n",
      "OPTIMIZACIÓN DE THRESHOLD\n",
      "============================================================\n",
      "Mejor modelo: Gradient Boosting\n",
      "Best threshold: 0.390\n",
      "Best F1 Score: 0.8339\n",
      "\n",
      "Con threshold 0.390:\n",
      "Accuracy: 0.8221\n",
      "F1 Score: 0.8339\n",
      "\n",
      "============================================================\n",
      "VOTING CLASSIFIER (Ensemble)\n",
      "============================================================\n",
      "Voting Classifier Results:\n",
      "Accuracy: 0.8226\n",
      "F1 Score: 0.8238\n",
      "ROC AUC: 0.9099\n",
      "\n",
      "Comparación con Gradient Boosting:\n",
      "  Mejora en F1: -0.0017\n",
      "\n",
      "============================================================\n",
      "ENTRENANDO MODELO FINAL\n",
      "============================================================\n",
      "Usando Gradient Boosting como modelo final\n",
      "¡Modelo final entrenado con éxito!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =====================\n",
    "# 1. Feature engineering (TU VERSIÓN)\n",
    "# =====================\n",
    "X_fe = X.copy()\n",
    "\n",
    "# Interacciones simples (mejoran LR)\n",
    "X_fe[\"Food_Drinks\"] = X_fe[\"Food\"] + X_fe[\"Drinks\"]\n",
    "X_fe[\"Spending\"] = X_fe[\"Food\"] * X_fe[\"Drinks\"]\n",
    "\n",
    "# Quitamos la variable con leakage\n",
    "X_fe = X_fe.drop(columns=[\"AvgTime\"])\n",
    "\n",
    "# =====================\n",
    "# 2. Columnas\n",
    "# =====================\n",
    "X_fe['Age'] = X_fe['Age'].fillna(X_fe['Age'].median())\n",
    "X_fe['Age_Group'] = pd.cut(X_fe['Age'], \n",
    "                          bins=[0, 25, 35, 45, 55, 100],\n",
    "                          labels=['<25', '25-35', '35-45', '45-55', '55+'])\n",
    "X_fe['Is_Young'] = (X_fe['Age'] < 30).astype(int)\n",
    "X_fe['Is_Senior'] = (X_fe['Age'] > 50).astype(int)\n",
    "\n",
    "# Opinion features\n",
    "X_fe['Opinion_Length'] = X_fe['Opinion'].str.len().fillna(0)\n",
    "X_fe['Has_Opinion'] = X_fe['Opinion'].notna().astype(int)\n",
    "\n",
    "# Sentimiento básico\n",
    "def simple_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    pos_words = ['good', 'great', 'excellent', 'amazing', 'love', 'best', 'awesome', 'perfect', 'fantastic']\n",
    "    neg_words = ['bad', 'worst', 'terrible', 'awful', 'hate', 'disappointing', 'poor', 'boring', 'waste']\n",
    "    \n",
    "    pos_count = sum(1 for word in pos_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in neg_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return 1\n",
    "    elif neg_count > pos_count:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "X_fe['Sentiment'] = X['Opinion'].apply(simple_sentiment)\n",
    "X_fe['Sentiment_Score'] = X_fe['Sentiment'].astype(int)\n",
    "\n",
    "# TicketInfo parsing\n",
    "X_fe[\"Ticket_Zone\"] = X[\"TicketInfo\"].str.split(\"/\").str[0]\n",
    "X_fe[\"Ticket_Row\"] = X[\"TicketInfo\"].str.split(\"/\").str[1].astype(float)\n",
    "X_fe[\"Ticket_Size\"] = X[\"TicketInfo\"].str.split(\"/\").str[2]\n",
    "X_fe['Is_Front_Row'] = (X_fe['Ticket_Row'] <= 10).astype(int)\n",
    "\n",
    "# Añadir más features de ticket\n",
    "X_fe['Is_VIP_Zone'] = X_fe['Ticket_Zone'].str.contains('VIP', case=False, na=False).astype(int)\n",
    "\n",
    "# Imputar valores faltantes\n",
    "# for col in ['PreferedAlbum', 'Concert', 'Ticket_Zone', 'Ticket_Size', 'Age_Group']:\n",
    "#     X_fe[col] = X_fe[col].fillna('Unknown')\n",
    "\n",
    "# for col in ['Vinyl', 'VIP']:\n",
    "#     X_fe[col] = X_fe[col].fillna('Unknown')\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in X_fe.columns:\n",
    "    if X_fe[col].dtype == 'bool':\n",
    "        X_fe[col] = X_fe[col].astype(int)\n",
    "\n",
    "# =====================\n",
    "# 3. Pipelines CORREGIDOS (matriz densa)\n",
    "# =====================\n",
    "num_cols = X_fe.select_dtypes(\"float64\").columns\n",
    "cat_cols = X_fe.select_dtypes(\"object\").columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# OneHotEncoder CON sparse_output=False para matriz densa\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\",\n",
    "        min_frequency=20,\n",
    "        sparse_output=False  # <--- ESTA ES LA CLAVE\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 4. PROBAR MODELOS (todos compatibles con matrices densas)\n",
    "# =====================\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_fe, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# MODELO 1: Random Forest (funciona bien)\n",
    "# =====================\n",
    "print(\"=\" * 60)\n",
    "print(\"MODELO 1: Random Forest\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "clf_rf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_val)\n",
    "y_proba_rf = clf_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_rf):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# MODELO 2: Gradient Boosting (Sklearn)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELO 2: Gradient Boosting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "clf_gb = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        subsample=0.8\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_gb.fit(X_train, y_train)\n",
    "y_pred_gb = clf_gb.predict(X_val)\n",
    "y_proba_gb = clf_gb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_gb):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_gb):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_gb):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# MODELO 3: HistGradientBoosting (OPTIMIZADO)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELO 3: HistGradientBoosting (Recomendado)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "clf_hgb = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        max_iter=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        min_samples_leaf=20,\n",
    "        l2_regularization=0.1,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_hgb.fit(X_train, y_train)\n",
    "y_pred_hgb = clf_hgb.predict(X_val)\n",
    "y_proba_hgb = clf_hgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_hgb):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_hgb):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_hgb):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# MODELO 4: KNeighbors (funciona con densas)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELO 4: k-Nearest Neighbors\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "clf_knn = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", KNeighborsClassifier(\n",
    "        n_neighbors=50,\n",
    "        weights='distance',\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(X_val)\n",
    "y_proba_knn = clf_knn.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_knn):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_knn):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_knn):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# MODELO 5: Logistic Regression (tu original)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODELO 5: Logistic Regression (L1)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf_lr = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"selector\", SelectFromModel(\n",
    "        LogisticRegression(penalty=\"l1\", solver=\"saga\", C=0.1, max_iter=1000)\n",
    "    )),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l1\",\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred_lr = clf_lr.predict(X_val)\n",
    "y_proba_lr = clf_lr.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_lr):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# COMPARATIVA\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARATIVA DE MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "for name, y_pred, y_proba in [\n",
    "    ('Random Forest', y_pred_rf, y_proba_rf),\n",
    "    ('Gradient Boosting', y_pred_gb, y_proba_gb),\n",
    "    ('HistGradientBoosting', y_pred_hgb, y_proba_hgb),\n",
    "    ('KNN', y_pred_knn, y_proba_knn),\n",
    "    ('Logistic Regression', y_pred_lr, y_proba_lr)\n",
    "]:\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_val, y_pred),\n",
    "        'F1 Score': f1_score(y_val, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_val, y_proba)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('F1 Score', ascending=False)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# =====================\n",
    "# THRESHOLD OPTIMIZATION PARA EL MEJOR MODELO\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMIZACIÓN DE THRESHOLD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Mejor modelo: {best_model_name}\")\n",
    "\n",
    "if best_model_name == 'HistGradientBoosting':\n",
    "    best_clf = clf_hgb\n",
    "    y_probs = y_proba_hgb\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_clf = clf_rf\n",
    "    y_probs = y_proba_rf\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_clf = clf_gb\n",
    "    y_probs = y_proba_gb\n",
    "elif best_model_name == 'Logistic Regression':\n",
    "    best_clf = clf_lr\n",
    "    y_probs = y_proba_lr\n",
    "else:\n",
    "    best_clf = clf_knn\n",
    "    y_probs = y_proba_knn\n",
    "\n",
    "# Buscar mejor threshold\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "scores = [f1_score(y_val, y_probs > t) for t in thresholds]\n",
    "\n",
    "best_threshold = thresholds[np.argmax(scores)]\n",
    "best_score = max(scores)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.3f}\")\n",
    "print(f\"Best F1 Score: {best_score:.4f}\")\n",
    "\n",
    "# Resultados con threshold óptimo\n",
    "y_pred_optimal = (y_probs > best_threshold).astype(int)\n",
    "print(f\"\\nCon threshold {best_threshold:.3f}:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_val, y_pred_optimal):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# VOTING CLASSIFIER (opcional)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VOTING CLASSIFIER (Ensemble)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Tomar los 3 mejores modelos\n",
    "top_3_models = results_df.head(3)['Model'].values\n",
    "\n",
    "estimators = []\n",
    "for model_name in top_3_models:\n",
    "    if model_name == 'HistGradientBoosting':\n",
    "        estimators.append(('hgb', HistGradientBoostingClassifier(\n",
    "            max_iter=300, learning_rate=0.05, max_depth=7,\n",
    "            min_samples_leaf=20, random_state=42, class_weight='balanced'\n",
    "        )))\n",
    "    elif model_name == 'Random Forest':\n",
    "        estimators.append(('rf', RandomForestClassifier(\n",
    "            n_estimators=200, max_depth=15, class_weight='balanced',\n",
    "            random_state=42, n_jobs=-1\n",
    "        )))\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        estimators.append(('gb', GradientBoostingClassifier(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            random_state=42\n",
    "        )))\n",
    "\n",
    "if estimators:\n",
    "    voting_clf = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"voting\", VotingClassifier(\n",
    "            estimators=estimators,\n",
    "            voting='soft',\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    y_pred_voting = voting_clf.predict(X_val)\n",
    "    y_proba_voting = voting_clf.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    print(f\"Voting Classifier Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_voting):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_val, y_pred_voting):.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_val, y_proba_voting):.4f}\")\n",
    "    \n",
    "    # Comparar con el mejor modelo individual\n",
    "    print(f\"\\nComparación con {best_model_name}:\")\n",
    "    print(f\"  Mejora en F1: {f1_score(y_val, y_pred_voting) - results_df.iloc[0]['F1 Score']:.4f}\")\n",
    "\n",
    "# =====================\n",
    "# ENTRENAR MODELO FINAL\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENTRENANDO MODELO FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Usar el mejor modelo individual o el voting\n",
    "if 'voting_clf' in locals() and f1_score(y_val, y_pred_voting) > results_df.iloc[0]['F1 Score']:\n",
    "    final_model = voting_clf\n",
    "    print(\"Usando Voting Classifier como modelo final\")\n",
    "else:\n",
    "    final_model = best_clf\n",
    "    print(f\"Usando {best_model_name} como modelo final\")\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "final_model.fit(X_fe, y)\n",
    "print(\"¡Modelo final entrenado con éxito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2218436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos de entrenamiento...\n",
      "Train - Columnas numéricas: 7\n",
      "Train - Columnas categóricas: 9\n",
      "Train - Total columnas: 16\n",
      "\n",
      "Entrenando modelo...\n",
      "F1 Score en validation: 0.8253\n",
      "Accuracy en validation: 0.8241\n",
      "\n",
      "Preparando datos de test...\n",
      "Test - Total columnas: 21\n",
      "Test después de ajuste - Total columnas: 21\n",
      "\n",
      "Haciendo predicciones...\n",
      "\n",
      "Submission creado:\n",
      "Número de predicciones: 2854\n",
      "FreePass positivos: 1379 (48.3%)\n",
      "Guardado como 'submission_final.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =====================\n",
    "# 1. FUNCIÓN PARA PREPARAR DATOS (USADA EN TRAIN Y TEST)\n",
    "# =====================\n",
    "def prepare_data(df, is_train=True):\n",
    "    \"\"\"Prepara datos de manera consistente para train y test\"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # Eliminar columnas que no queremos\n",
    "    if 'AvgTime' in df_fe.columns:\n",
    "        df_fe = df_fe.drop(columns=['AvgTime'])\n",
    "    \n",
    "    # Guardar Id si existe (para submission)\n",
    "    if 'Id' in df_fe.columns and is_train == False:\n",
    "        ids = df_fe['Id']\n",
    "        df_fe = df_fe.drop(columns=['Id'])\n",
    "    else:\n",
    "        ids = None\n",
    "    \n",
    "    # Features básicas\n",
    "    df_fe[\"Food_Drinks\"] = df_fe[\"Food\"] + df_fe[\"Drinks\"]\n",
    "    df_fe[\"Spending\"] = df_fe[\"Food\"] * df_fe[\"Drinks\"]\n",
    "    \n",
    "    # Age features\n",
    "    df_fe['Age'] = df_fe['Age'].fillna(df_fe['Age'].median())\n",
    "    df_fe['Is_Young'] = (df_fe['Age'] < 30).astype(int)\n",
    "    df_fe['Is_Senior'] = (df_fe['Age'] > 50).astype(int)\n",
    "    \n",
    "    # Opinion features\n",
    "    df_fe['Opinion_Length'] = df_fe['Opinion'].str.len().fillna(0)\n",
    "    df_fe['Has_Opinion'] = df_fe['Opinion'].notna().astype(int)\n",
    "    \n",
    "    # TicketInfo\n",
    "    df_fe[\"Ticket_Zone\"] = df_fe[\"TicketInfo\"].str.split(\"/\").str[0]\n",
    "    df_fe[\"Ticket_Row\"] = pd.to_numeric(df_fe[\"TicketInfo\"].str.split(\"/\").str[1], errors='coerce')\n",
    "    df_fe[\"Ticket_Size\"] = df_fe[\"TicketInfo\"].str.split(\"/\").str[2]\n",
    "    df_fe['Is_Front_Row'] = (df_fe['Ticket_Row'] <= 10).astype(int)\n",
    "    df_fe['Is_VIP_Zone'] = df_fe['Ticket_Zone'].str.contains('VIP', case=False, na=False).astype(int)\n",
    "    \n",
    "    # Age Group\n",
    "    df_fe['Age_Group'] = pd.cut(df_fe['Age'], \n",
    "                               bins=[0, 25, 35, 45, 55, 100],\n",
    "                               labels=['<25', '25-35', '35-45', '45-55', '55+'])\n",
    "    \n",
    "    # Imputar categóricas\n",
    "    # for col in ['PreferedAlbum', 'Concert', 'Ticket_Zone', 'Ticket_Size', 'Age_Group']:\n",
    "    #     df_fe[col] = df_fe[col].fillna('Unknown')\n",
    "    \n",
    "    # for col in ['Vinyl', 'VIP']:\n",
    "    #     df_fe[col] = df_fe[col].fillna('Unknown')\n",
    "    \n",
    "    # Asegurar tipos\n",
    "    for col in df_fe.columns:\n",
    "        if df_fe[col].dtype == 'bool':\n",
    "            df_fe[col] = df_fe[col].astype(int)\n",
    "    \n",
    "    return df_fe, ids\n",
    "\n",
    "# =====================\n",
    "# 2. PREPARAR DATOS DE TRAIN\n",
    "# =====================\n",
    "print(\"Preparando datos de entrenamiento...\")\n",
    "X_fe, _ = prepare_data(X, is_train=True)\n",
    "\n",
    "# Identificar columnas\n",
    "num_cols = X_fe.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "cat_cols = X_fe.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Train - Columnas numéricas: {len(num_cols)}\")\n",
    "print(f\"Train - Columnas categóricas: {len(cat_cols)}\")\n",
    "print(f\"Train - Total columnas: {len(num_cols) + len(cat_cols)}\")\n",
    "\n",
    "# =====================\n",
    "# 3. CREAR PIPELINE\n",
    "# =====================\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(\n",
    "        handle_unknown=\"ignore\",\n",
    "        sparse_output=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline completo\n",
    "pipeline = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        max_iter=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        min_samples_leaf=20,\n",
    "        l2_regularization=0.1,\n",
    "        early_stopping=True,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 4. ENTRENAR MODELO\n",
    "# =====================\n",
    "print(\"\\nEntrenando modelo...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_fe, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "y_pred = pipeline.predict(X_val)\n",
    "print(f\"F1 Score en validation: {f1_score(y_val, y_pred):.4f}\")\n",
    "print(f\"Accuracy en validation: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "\n",
    "# =====================\n",
    "# 5. PREPARAR Y PREDECIR TEST\n",
    "# =====================\n",
    "print(\"\\nPreparando datos de test...\")\n",
    "X_test_fe, test_ids = prepare_data(df_test, is_train=False)\n",
    "\n",
    "# Verificar que test tenga las mismas columnas que train\n",
    "print(f\"Test - Total columnas: {X_test_fe.shape[1]}\")\n",
    "\n",
    "# Asegurar que test tiene las mismas columnas en el mismo orden\n",
    "missing_cols = set(X_fe.columns) - set(X_test_fe.columns)\n",
    "extra_cols = set(X_test_fe.columns) - set(X_fe.columns)\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Columnas faltantes en test: {missing_cols}\")\n",
    "    # Añadir columnas faltantes con valores por defecto\n",
    "    for col in missing_cols:\n",
    "        X_test_fe[col] = 0 if X_fe[col].dtype in ['int64', 'float64'] else 'Unknown'\n",
    "\n",
    "if extra_cols:\n",
    "    print(f\"Columnas extra en test: {extra_cols}\")\n",
    "    # Eliminar columnas extra\n",
    "    X_test_fe = X_test_fe.drop(columns=list(extra_cols))\n",
    "\n",
    "# Reordenar columnas para que coincidan con train\n",
    "X_test_fe = X_test_fe[X_fe.columns]\n",
    "\n",
    "print(f\"Test después de ajuste - Total columnas: {X_test_fe.shape[1]}\")\n",
    "\n",
    "# =====================\n",
    "# 6. HACER PREDICCIONES\n",
    "# =====================\n",
    "print(\"\\nHaciendo predicciones...\")\n",
    "y_proba_test = pipeline.predict_proba(X_test_fe)[:, 1]\n",
    "\n",
    "# Aplicar threshold (ajusta según lo que optimizaste)\n",
    "best_threshold = 0.5\n",
    "preds = (y_proba_test > best_threshold).astype(int)\n",
    "\n",
    "# =====================\n",
    "# 7. CREAR SUBMISSION\n",
    "# =====================\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"FreePass\": preds.astype(bool)\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission creado:\")\n",
    "print(f\"Número de predicciones: {len(submission)}\")\n",
    "print(f\"FreePass positivos: {submission['FreePass'].sum()} ({submission['FreePass'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Guardar\n",
    "submission.to_csv(\"submission_final.csv\", index=False)\n",
    "print(\"Guardado como 'submission_final.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
